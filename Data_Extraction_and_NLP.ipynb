{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install numpy\n",
        "!pip install io\n",
        "!pip install json\n",
        "!pip install numpy \n",
        "!pip install requests\n",
        "!pip install syllables\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzrE_H_tsCDg",
        "outputId": "2b02e3cb-c340-4871-f49c-013b9d95b820"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement io (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for io\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: syllables in /usr/local/lib/python3.8/dist-packages (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from syllables) (5.2.0)\n",
            "Requirement already satisfied: cmudict<2.0.0,>=1.0.11 in /usr/local/lib/python3.8/dist-packages (from syllables) (1.0.13)\n",
            "Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /usr/local/lib/python3.8/dist-packages (from cmudict<2.0.0,>=1.0.11->syllables) (5.10.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->syllables) (3.12.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import json\n",
        "import numpy as np\n",
        "from requests.models import MissingSchema \n",
        "import syllables\n",
        "import nltk"
      ],
      "metadata": {
        "id": "g7QAtzM4sipH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvjIKQenviaI",
        "outputId": "9585a94b-ab38-4367-cff1-3f9c4fc88cfe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Input.csv')[['URL_ID','URL']]"
      ],
      "metadata": {
        "id": "glI-hdGYtjou"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df.iterrows():\n",
        "    # Extract the URL and URL ID from the row\n",
        "    url = row['URL']\n",
        "    url_id = row['URL_ID']\n",
        "\n",
        "    # Send a request to the webpage\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content of the webpage using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract the textual content of the article\n",
        "    article_text = \"\"\n",
        "    for p in soup.find_all('p'):\n",
        "        if p.find('img'):\n",
        "            # Ignore if an image is nested within a <p> tag\n",
        "            continue\n",
        "        else:\n",
        "            article_text += p.get_text()\n",
        "\n",
        "    # Save the extracted article text to a text file\n",
        "    output_file = f\"{url_id}.txt\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(article_text)\n",
        "\n",
        "    print(f\"Extracted article from {url} and saved to {output_file}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCiW0slCtmg9",
        "outputId": "6f796a61-57bf-4248-e38c-6cf3db1ca06a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted article from https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/ and saved to 37.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/ and saved to 38.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/ and saved to 39.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/ and saved to 40.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/ and saved to 41.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/ and saved to 42.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/ and saved to 43.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/ and saved to 44.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/ and saved to 45.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/ and saved to 46.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/ and saved to 47.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/ and saved to 48.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/ and saved to 49.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/ and saved to 50.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/ and saved to 51.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/ and saved to 52.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/ and saved to 53.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/ and saved to 54.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/evolution-of-advertising-industry/ and saved to 55.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/ and saved to 56.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/ and saved to 57.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/ and saved to 58.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/ and saved to 59.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/ and saved to 60.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/ and saved to 61.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/ and saved to 62.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/ and saved to 63.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/ and saved to 64.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/ and saved to 65.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-we-forecast-future-technologies/ and saved to 66.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/ and saved to 67.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/ and saved to 68.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/ and saved to 69.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/ and saved to 70.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/ and saved to 71.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/ and saved to 72.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/ and saved to 73.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/ and saved to 74.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/ and saved to 75.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/ and saved to 76.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/ and saved to 77.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/ and saved to 78.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/ and saved to 79.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/ and saved to 80.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/ and saved to 81.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/ and saved to 82.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/ and saved to 83.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/ and saved to 84.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/ and saved to 85.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/ and saved to 86.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/ and saved to 87.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/ and saved to 88.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/ and saved to 89.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/ and saved to 90.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/human-rights-outlook/ and saved to 91.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/ and saved to 92.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/ and saved to 93.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/ and saved to 94.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/ and saved to 95.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/ and saved to 96.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/ and saved to 97.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/ and saved to 98.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/ and saved to 99.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/ and saved to 100.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/travel-and-tourism-outlook/ and saved to 101.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/ and saved to 102.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/ and saved to 103.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/ and saved to 104.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/ and saved to 105.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/ and saved to 106.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/ and saved to 107.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/ and saved to 108.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis/ and saved to 109.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding/ and saved to 110.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-2/ and saved to 111.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/ and saved to 112.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-3/ and saved to 113.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work/ and saved to 114.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding-2/ and saved to 115.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-4/ and saved to 116.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/ and saved to 117.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-3/ and saved to 118.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-4/ and saved to 119.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/why-scams-like-nirav-modi-happen-with-indian-banks/ and saved to 120.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/ and saved to 121.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy-2/ and saved to 122.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy-2/ and saved to 123.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-3/ and saved to 124.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/should-celebrities-be-allowed-to-join-politics/ and saved to 125.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-prepared-is-india-to-tackle-a-possible-covid-19-outbreak/ and saved to 126.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work/ and saved to 127.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/controversy-as-a-marketing-strategy/ and saved to 128.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry/ and saved to 129.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets/ and saved to 130.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-are-the-key-policies-that-will-mitigate-the-impacts-of-covid-19-on-the-world-of-work/ and saved to 131.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/marketing-drives-results-with-a-focus-on-problems/ and saved to 132.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/continued-demand-for-sustainability/ and saved to 133.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-disease-covid-19-effect-the-impact-and-role-of-mass-media-during-the-pandemic/ and saved to 134.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/ and saved to 135.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/why-is-there-a-severe-immunological-and-inflammatory-explosion-in-those-affected-by-sarms-covid-19/ and saved to 136.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/what-do-you-think-is-the-lesson-or-lessons-to-be-learned-with-covid-19/ and saved to 137.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/coronavirus-the-unexpected-challenge-for-the-european-union/ and saved to 138.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/industrial-revolution-4-0-pros-and-cons/ and saved to 139.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy/ and saved to 140.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-2/ and saved to 141.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy/ and saved to 142.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/ and saved to 143.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/ and saved to 144.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/blockchain-in-fintech/ and saved to 145.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/blockchain-for-payments/ and saved to 146.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/the-future-of-investing/ and saved to 147.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/big-data-analytics-in-healthcare/ and saved to 148.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/business-analytics-in-the-healthcare-industry/ and saved to 149.txt.\n",
            "Extracted article from https://insights.blackcoffer.com/challenges-and-opportunities-of-big-data-in-healthcare/ and saved to 150.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_personal_pronouns(text):\n",
        "  personal_pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
        "  # Define a regular expression pattern to match the personal pronouns\n",
        "  pattern = r'\\b(' + '|'.join(personal_pronouns) + r')\\b'\n",
        "  # Compile the regular expression pattern\n",
        "  regex = re.compile(pattern, flags=re.IGNORECASE)\n",
        "  # Count the number of personal pronouns in the text\n",
        "  count = len(regex.findall(text))\n",
        "  return count"
      ],
      "metadata": {
        "id": "cUPRm-2BznLq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personalpronouns=[]\n",
        "for i, row in df.iterrows():\n",
        "    # Extract the URL and URL ID from the row\n",
        "    url_id = row['URL_ID']\n",
        "    with open(f'{url_id}.txt', 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        personalpronouns.append(count_personal_pronouns(text))"
      ],
      "metadata": {
        "id": "AEjks6kZztZ9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_stop_words(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        stop_words = [line.strip() for line in f]\n",
        "    return set(stop_words)\n",
        "    \n",
        "stop_words_file = 'stop_words_Auditor.txt'\n",
        "stop_words_Auditor = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_Geographic.txt'\n",
        "stop_words_Geographic = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_Currencies.txt'\n",
        "stop_words_Currencies = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_DatesandNumbers.txt'\n",
        "stop_words_DatesandNumbers = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_generic.txt'\n",
        "stop_words_generic = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_GenericLong.txt'\n",
        "stop_words_GenericLong = load_stop_words(stop_words_file)\n",
        "\n",
        "stop_words_file = 'stop_words_Names.txt'\n",
        "stop_words_Names = load_stop_words(stop_words_file)"
      ],
      "metadata": {
        "id": "-D_pWrIZtpJs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Set up NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define a function for text normalization\n",
        "def normalize_text(text):\n",
        "    # Remove all non-word characters and convert to lowercase\n",
        "    text = re.sub(r'[^\\w.]', ' ', text)\n",
        "    text = text.lower().strip()\n",
        "    text = text.replace('.', ' FULL_STOP_TOKEN ')\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    words = [word for word in words if word not in stop_words_Auditor]\n",
        "    words = [word for word in words if word not in stop_words_Geographic]\n",
        "    words = [word for word in words if word not in stop_words_Currencies]\n",
        "    words = [word for word in words if word not in stop_words_DatesandNumbers]\n",
        "    words = [word for word in words if word not in stop_words_generic]\n",
        "    words = [word for word in words if word not in stop_words_GenericLong]\n",
        "    words = [word for word in words if word not in stop_words_Names]\n",
        "    # Lemmatize the words\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # Join the words back into a single string\n",
        "    text = ' '.join(words)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nvcWwAtt9Mo",
        "outputId": "0169de52-0862-46b2-e366-c805195e5885"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df.iterrows():\n",
        "    # Extract the URL and URL ID from the row\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    # Read the text from the file\n",
        "    with open(f'{url_id}.txt', 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Clean and normalize the text\n",
        "    \n",
        "    normalized_text = normalize_text(text)\n",
        "  \n",
        "    # Write the normalized text to the file\n",
        "    with open(f'{url_id}.txt', 'w', encoding='utf-8') as file:\n",
        "        file.write(normalized_text)"
      ],
      "metadata": {
        "id": "6lHa0X6Ru4Sk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = set()\n",
        "\n",
        "# Load positive words from file\n",
        "with open('positive-words.txt', 'r') as f:\n",
        "    positive_words = set(word.strip() for word in f.readlines())\n",
        "\n",
        "def get_positive_score(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the number of positive words in the text\n",
        "    positive_count = sum(1 for word in words if word in positive_words)\n",
        "\n",
        "    total_words = len(words)\n",
        "    if total_words == 0:\n",
        "        return 0\n",
        "    positive_score = positive_count / total_words\n",
        "\n",
        "    return positive_score"
      ],
      "metadata": {
        "id": "u4Qm2VHou-S-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_words = set()\n",
        "\n",
        "# Load positive words from file\n",
        "with open('negative-words.txt', 'r') as f:\n",
        "    negative_words = set(word.strip() for word in f.readlines())\n",
        "\n",
        "def get_negative_score(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the number of positive words in the text\n",
        "    negative_count = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    total_words = len(words)\n",
        "    if total_words == 0:\n",
        "        return 0\n",
        "    negative_score = negative_count / total_words\n",
        "\n",
        "    return negative_score"
      ],
      "metadata": {
        "id": "MSzTuP6vvzjE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "def count_syllables(word):\n",
        "    vowels = 'aeiouy'\n",
        "    num_vowels = 0\n",
        "    for i in range(len(word)):\n",
        "        if word[i].lower() in vowels:\n",
        "            num_vowels += 1\n",
        "            if i > 0 and word[i-1].lower() in vowels:\n",
        "                num_vowels -= 1\n",
        "    if word.endswith('e'):\n",
        "        num_vowels -= 1\n",
        "    if num_vowels == 0:\n",
        "        num_vowels = 1\n",
        "    return num_vowels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPAQDJAezak8",
        "outputId": "bc6c4c78-6e5d-4d4a-b4f5-bbf45f7cf8da"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_complex_words(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the number of complex words\n",
        "    count = 0\n",
        "    for word in words:\n",
        "        # Get the number of syllables in the word\n",
        "        syllable_count = syllables.estimate(word)\n",
        "\n",
        "        # Count the word as complex if it has more than two syllables\n",
        "        if syllable_count > 2:\n",
        "            count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "def calculate_percentage_of_complex_words(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(text)\n",
        "    if total_words == 0:\n",
        "        return 0\n",
        "    num_complex_words = count_complex_words(text)\n",
        "    percentage_of_complex_words = (num_complex_words / total_words)\n",
        "    return percentage_of_complex_words"
      ],
      "metadata": {
        "id": "PfgYPWknwN3O"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_syllables(word):\n",
        "    \"\"\"\n",
        "    Count the number of syllables in a word.\n",
        "\n",
        "    Args:\n",
        "        word (str): The word to count syllables for.\n",
        "\n",
        "    Returns:\n",
        "        int: The number of syllables in the word.\n",
        "    \"\"\"\n",
        "    # Define a list of vowels\n",
        "    vowels = ['a', 'e', 'i', 'o', 'u', 'y']\n",
        "\n",
        "    # Remove trailing \"es\" and \"ed\" from the word\n",
        "    word = word.rstrip('es')\n",
        "    word = word.rstrip('ed')\n",
        "\n",
        "    # Count the number of vowels in the word\n",
        "    syllables = 0\n",
        "    prev_char = None\n",
        "    for char in word:\n",
        "        if char in vowels and (prev_char is None or prev_char not in vowels):\n",
        "            syllables += 1\n",
        "        prev_char = char\n",
        "\n",
        "    # Handle special cases where the word ends in \"le\"\n",
        "    if word.endswith('le') and word[-3] not in vowels:\n",
        "        syllables += 1\n",
        "\n",
        "    # Handle special cases where the word has no vowels\n",
        "    if syllables == 0:\n",
        "        syllables = 1\n",
        "\n",
        "    return syllables"
      ],
      "metadata": {
        "id": "7GQQzMYFwQQp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count(word):\n",
        "    words = text.split()\n",
        "    count = 0\n",
        "    for word in words:\n",
        "        if word != 'FULL_STOP_TOKEN':\n",
        "            count += len(word)\n",
        "    return count"
      ],
      "metadata": {
        "id": "Nd1dgLOywTb7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive=[]\n",
        "negative=[]\n",
        "polarity=[]\n",
        "subjectivity=[]\n",
        "fogIndex=[]\n",
        "avgnum=[]\n",
        "complexwords=[]\n",
        "syllable=[]\n",
        "wordcount=[]\n",
        "avgwordlength=[]\n",
        "for i, row in df.iterrows():\n",
        "    # Extract the URL and URL ID from the row\n",
        "    url_id = row['URL_ID']\n",
        "    with open(f'{url_id}.txt', 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    \n",
        "    sentences = text.split('FULL_STOP_TOKEN')\n",
        "    num_sentences = len(sentences)\n",
        "    \n",
        "    # Remove the FULL_STOP_TOKEN from the text\n",
        "    text = text.replace('FULL_STOP_TOKEN', \"\")\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "    # Count the words\n",
        "    num_words = len(words)\n",
        "    \n",
        "    positive_score = get_positive_score(text)\n",
        "    positive.append(positive_score)\n",
        "    \n",
        "    negative_score = get_negative_score(text)\n",
        "    negative.append(negative_score)\n",
        "    \n",
        "    temp=((positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001))\n",
        "    polarity.append(temp)\n",
        "    \n",
        "    temp2=(positive_score + negative_score)/ ((num_words) + 0.000001)\n",
        "    subjectivity.append(temp2)\n",
        "    \n",
        "    if num_sentences==0:\n",
        "        Average_Sentence_Length=0\n",
        "    else:\n",
        "        Average_Sentence_Length= num_words/num_sentences\n",
        "    Percentage_of_Complex_words=calculate_percentage_of_complex_words(text)\n",
        "    fogIndex.append(0.4 * (Average_Sentence_Length + Percentage_of_Complex_words))\n",
        "    \n",
        "    avgnum.append(Average_Sentence_Length)\n",
        "    \n",
        "    complexwords.append(count_complex_words(text))\n",
        "    \n",
        "    wordcount.append(num_words)\n",
        "    \n",
        "    syllable.append(count_syllables(text))\n",
        "    \n",
        "    \n",
        "    if num_words==0:\n",
        "        Average=0\n",
        "    else:\n",
        "        Average= count(text)/num_words\n",
        "    \n",
        "    avgwordlength.append(Average)"
      ],
      "metadata": {
        "id": "pjqCpQz6wVw4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"POSITIVE SCORE\"]=positive\n",
        "df[\"NEGATIVE SCORE\"]=negative\n",
        "df[\"POLARITY SCORE\"]=polarity\n",
        "df[\"SUBJECTIVITY SCORE\"]=subjectivity\n",
        "df[\"FOG INDEX\"]=fogIndex\n",
        "df[\"AVG NUMBER OF WORDS PER SENTENCE\"]=avgnum\n",
        "df[\"COMPLEX WORD COUNT\"]=complexwords\n",
        "df[\"WORD COUNT\"]=wordcount\n",
        "df[\"SYLLABLE PER WORD\"]=syllable\n",
        "df[\"PERSONAL PRONOUNS\"]=personalpronouns\n",
        "df[\"AVG WORD LENGTH\"]=avgwordlength"
      ],
      "metadata": {
        "id": "dHk0nKkVwY2M"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('Output Data Structure.xlsx', index=False)"
      ],
      "metadata": {
        "id": "UbzSkPDiwcMK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rvVWp0Iwerg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}